<header class="mini">
<h2>DogBot</h2>
<p>Experimenting reinforcement learning on a playable character</p>
</header>

<h3>High-Level character controll<h3>

<p>Reinforcement learning have been a trending topic recently with the Deep Learning techniques. Various interesting applications have been made from playing games (Atari, Go, StarCraft, etc) to controlling torque-actuators for motion control in robotic simulations (biped run, robotic hand solving rubik's cube, etc). Here we want to experiment with high level controls of a character, which already have its animations and controller, to do simple tasks like collect or fetch an object.
</p>

<p>Our choosen character is a dog (we call it DogBot for now). It can stand, walk, trot, run, jump and crouch and we train it to choose between those actions to accomplish a desired task.
</p>




idea - high level character control
idea - basic learned actions controlled by a bigger "brain"
basic input -  forward, backward, left, right, jump crouch

training
	- collect pink objects
		- binary reward {0,1}
	- reach stand pink pads
		- inside time reward
	- visual observation
	- forward bias
	- continuous action space (-1,1)
		- network output scaling
	- discrete action space {backward, stand, walk, trot, run}, {left, straight, right}
		- forward bias on reward
	- puppo like
		- high level discrete actions
		- vector observations of direction, distance, borders and velocity
	- environment
		- difficult
			- # items
			- size
			- possible actions
	- reward
		- shape behavior
			- binary
			- increasing
			- time penalty
			- action penalty
		- forward bias
		- difficult to attain the desired end result
	- result
		- puppo like
			- works good, "complete" information of ambient
		- visual observation
			- partial information
			- movement tied to vision, lack of attention
			- independent action branches, hard to train together
			- nonoptimal behavior, forward overfit
		- generalization
			- object shape (because of color?)
			- area size
			
			
	