<header class="mini">
<h2>Unity Animation</h2>
<p>Creating a playable character</p>
</header>

<h3>Introduction</h3>

<p>Creating a playable character in Unity takes more work than just having a model and animation clips. In the next sections we are going to look at the basics of how to put together the model and its animation clips in a playable character starting from a <i>*.fbx</i> file containing the data. Our character will be a dog with basic move-set: idle, walk, trot, run, jump and crouch.</p>


<h3>Importing, Rigging & Avatar</h3>

<p>Importing an <i>fbx</i>  file into Unity is as simple as placing it in the <code>"YourProjectName"/Assets/</code> folder. Inside Unity it will look like a single object with an side arrow. Expanding it will show everything contained inside, like the armature, skinning, materials, mesh, animation clips or anything else.</p>

<img class="image fit" src="images/fbx.png"></img>

<p>In our case we have a dog named "kolly". As soon as you select the fbx the inspector window  will have the import settings.</p>

<div class="spotlight">
	<div class="image flush"> <img class="image 50%" src="images/rigging.png"></img></div>
	<div class="inner2">
		<p>On the <i>rig</i> tab you can specify the following properties:
		<ul>
			<li><b>Animation type:</b> <code>humanoid</code> for humanoids and <code>generic</code> for any other type of characters.</li>
			<li><b>Avatar definition:</b> <code>no avatar</code>, <code>create from this model</code> and <code>copy from other avatar</code>. An avatar is an object that relates the bone's animation to the mesh deformation or <i>muscles definition</i>. It is very useful for humanoid characters because it let one connect different shaped bodies to the same animation. For example, you could use the same walking animation for characters with different height. Another point is: you can't use an AnimatorController without having an avatar, even if you don't plan to use various characters with different shapes.</li>
			<li><b>Root node:</b> the root bone of the skeleton (only appears for generic types).</li>
			<li><b>Skin weights:</b> Bone/mesh interaction weights import mode.</li>
		</ul>
		</p>
	</div>
</div>
<br>
<p>After configuring the rigging you must "apply" the modifications and Unity will process them.</p>


<h3>Animation clips: cut, loop and cycle</h3>

<p>The next tab after rig is the <i>Animation</i>. In this tab you can select to import (or not) animation clips, re-sample/compress its curves and edit animation clips properties.</p>

<img class="image fit" src="images/anim.png"></img>

<p>Following the general properties, there is a list of animation clips. When selecting any of the clips and scrolling down there will be options of how to export this clip.
<ul>
	<li><b>Length bar:</b> here one can cut the clip. It is useful for various situations, for example when all clips are in the same take, you can cut and separate them and also when fine tunning its length to fit in a given a controller and blend tree.</li>
	<li><b>Loop Time:</b> Enables the animation to loop.</li>
	<li><b>Loop Pose:</b> For animations where the final pose is different from the initial pose, enabling this option smooths the animation loop between poses.</li>
	<li><b>Cycle Time:</b> Normalized starting time of the animation \( \in [0,1]\). Useful to synchronize clips in a blend tree like walking/running.</li>
</ul>
</p>
<div style="margin: 3rem">
	<div class="image 50%" style="text-align: center">
	Without loop pose.<br>
	<video src="images/not_smooth.webm" controls></video>
	</div>
	<div class="image 50%" style="text-align: center">
	With loop pose.<br>
	<video src="images/smooth.webm" controls>
	</video>
	</div>
</div>
<br>
<h4>Root Motion Options</h4>

<p>Animation clips where the root bone transform (position/rotation/scale) changes along the clip are considered to have <i>root motion</i>. Unity takes the delta between the animation frames and apply this movement (rotations, translations and scale) to the entire game object. For example an walking animation where the root bone starts at position \(p_0\) and ends at \(p_1 \neq p_0\) would have a motion in the direction \(p_1 - p_0\) making the gameObject whose it is attached to move in the scene.</p>

<p>The options <code>Root Transform</code> control how the root motion should be interpreted by Unity. Enabling <code>Bake Into Pose</code> does not apply it to the gameObject but makes it part of the animation clip. One can choose separately which movements (transforms) to apply or bake, they are <code>Rotation</code>, <code>Transform Y</code>(vertical move), <code>Transform XZ</code>(horizontal move).</p>

Other options are:
<div class="spotlight">
	<div class="image flush"> <img class="image 50%" src="images/rootmotion.png"></img></div>
	<div class="inner2">
		<ul>
			<li><b>Curves:</b> Create additional parameter curve based on animation time, which can be used to control other effects/events.</li>
			<li><b>Events:</b> Enable to control external events based on animation time.</li>
			<li><b>Mask:</b> Control which bones to animate.</li>
			<li><b>Motion:</b> Choose from which bone comes the root motion if other than the root.</li>
		</ul>
	</div>
</div>

<!-- TODO fix video size -->
<div style="margin: 3rem;">
	<div class="image 50%" style="text-align: center; float: left;">
	With root motion.<br>
		<div class="video-container">
		<video width="428" height="334" src="images/rootmotion.webm" frameborder="0" controls></video>
		</div>
	</div>
	<div class="image 50%" style="text-align: center;">
		Baked root motion.<br>
		<div class="video-container">
		<video width="428" height="334" src="images/bakedrootmotion.webm" frameborder="0" controls></video>
		</div>
	</div>
</div>
<br>

<h3>Keyframe Edit & Preview</h3>

<p>It is possible to edit and preview each key-frame of an animation clip. While it isn't a graphical interactive tool, one can make simple modifications to the numeric values of the transformation (position, rotation and scale) of each bone and the root motion, adding/removing key-frames of the full clip or particular bones.</p>

<img class="image fit" src="images/animwindow.png"></img>

<p>The animation window can be opened by double click in any animation or in the menu <code>Window > Animation > Animation (CTRL+6)</code>. To enable the preview of the selected key-frame it is necessary to, after having the window open, select the proper gameObject in the scene.</p>

<h3>Animator & Character Controller</h3>
<div class="spotlight">
	<div class="image flush">
		<img class="image" src="images/animator.png"></img>
	</div>
	<div class="inner2">
		<p>In order to create an animated character it is necessary to have an <i>Animator</i> Component in the desired gameObject. This component requires a <code>Controller</code> which is a state machine for the animation clips, and an <code>Avatar</code>, in our case the one created when selecting the <i>Rig</i> properties while importing the fbx file. The other parameters are <code>Update Mode</code> which controls how the animation updates are made (synchronous or asynchronous with the physics engine), and <code>Culling Mode</code> which controls if and how the animation is played when the gameObject is not (or partially) visible.
		</p>
	</div>
</div>

<h4>Animator Controller</h4>

<p>The animator controller is a <i>state machine</i> where the behavior of the character animation is defined. It is composed of parameters, states, and transitions.</p>

<img class="image fit" src="images/animatorcontroller.png"></img>

<p>The parameters are created by the user on the "plus" sign, they can be of four types: boolean, float, integer or trigger (which is a boolean that resets its state when consumed by some transition). Those parameters can be used used to control both the transition conditions and the animation blending. They are accessed by their name and type from C#. The following example shows how to set state's machine variables.</p>
<div id="animatorSet"><script> loadGist("animatorSet",'https://gist.github.com/caioc2/6538f07e4d083c7ec046803cdfcb46a4.json');</script></div>
<p> where:
<ul>
    <li><code>void SetFloat(string name, float value, float dampTime, float deltaTime);</code></li>
	<li><code>void SetInteger(string name, int value);</code></li>
	<li><code>void SetBool(string name, float value);</code></li>
</ul>
The parameters can also be read with the equivalent "Get" functions.
</p>

<div class="spotlight">
	<div class="image flush">
		<img class="image" src="images/transition.png"></img>
	</div>
	<div class="inner2">
		<p>Transitions are descriptions of how and when to move between states. They are represented by the arrows between states and can be created by right click on a source state, selecting <code>Make transition</code> and then clicking on the destination state.
		The condition list is treated as a logic "and" among the selected variables and its values. For booleans it admits <code>true/false</code>, for floating point <code>less/greater than</code> and for integer <code>less/greater than, equal, not equal</code>. The logic operator "or" can be simulated by creating multiple transitions between the same two states. More complex conditions can also be handled by C# code and setting a single boolean as transition indicator afterward.</p>
		<div id="complexc"><script>loadGist('complexc','https://gist.github.com/caioc2/7d4d917f82b5b67385c78b5fcd5322be.json');</script></div>
		<p>In this example we check for not walking (steering/forward velocity) and other states like crouch, jump, if it is grounded and how much time it is in this condition to set the idle boolean.</p>
	</div>
</div>

<p>The transition settings are:</p>
<ul>
    <li><b>Has Exit Time:</b> When enabled forces the transition to happens only at a certain point in the animation. Even if all transition conditions are met, it will delay the transition until that point. It should be used wisely as this delay may appears to the user as lack of responsiveness for the controller.</li>
	<li><b>Exit Time:</b> The point in normalized animation clip length where the transition can occur.</li>
	<li><b>Fixed Time:</b> When enabled the transition time is taken in seconds, otherwise it is taken in normalized animation time.</li>
	<li><b>Transition Duration:</b> Duration of the transition.</li>
	<li><b>Transition offset:</b> Normalized time of where to start the animation which is being transitioned to.</li>
	<li><b>Interruption source:</b> How interruption should be handled, possible values are <code>None</code>, <code>Current State</code>, <code>Next State</code>, <code>Current then Next State</code> and <code>Next then Current State</code></li>
</ul>

<p>Finally, the states of the machine can contain a <i>single animation clip</i>, a <i>blend-tree of clips</i> or a <i>sub-state machine</i>. They are represented by the rectangular geometry and their color indicates the type of the state. They are:</p>
<ul>
    <li><font color="#35d035"><b>Entry</b></font>: When entering the (sub)state machine, it starts in this state.</li>
	<li><font color="#f09624"><b>Default</b></font>: When initializing, it starts in this state, there is always a unconditional transition from entry to the default state.</li>
	<li><font color="#dc1616"><b>Exit</b></font>: Leaves from the (sub)state machine.</li>
	<li><font color="#6fc5b6"><b>Any State</b></font>: A shortcut for creating transitions for all states. If all states can transit to a <i>X</i> state with the same condition, then one can use any <code>Any State -> X</code> as a shortcut, it also avoids cluttering the screen with transitions for each state. Transitions can only be crated from <i>Any State</i> to another state, not the inverse direction.</li>
	<li><font color="#999999"><b>Common</b></font>: Normal user defined states.</li>
</ul>

<p>Sub-state machines are <i>"state machines inside a state"</i>, they can be recognized by the  hexagonal form, instead of the rectangular. They are useful to organize complex behaviors and also avoiding cluttering the screen. They have their own entry and exit and an additional state <code>Up(Layer)</code> which goes back to the main state machine. Here we organized our Idle animation clips inside a sub-state machine.</p>

<p>By double clicking in a sub-state it goes into its own layer. The following figure show our Idle sub-state machine.</p>
<img class="image fit" src="images/substatemachine.png"></img>

<h4>Blend Trees</h4>

<img class="image fit" src="images/blendtree.png"></img>

<p>Inside each state, one can have a single animation clip or various clips mixed by some parameters. This animation "mixer" is called <i>Blend Tree</i>. Each entry in a blend tree can be an animation clip or another blend tree. While a single blend tree can have at maximum two parameters, any parameters of its child blend trees will appear on the parent. Their parameters are matched with the state machine parameters by name and it accepts only floating points.</p>
<p>In the left there is the inspector of a blend tree.</p>
<div class="spotlight">
	<div class="image flush">
		<img class="image" src="images/btdetail.png"></img>
	</div>
	<div class="inner2">
		<ul>
			<li><b>Blend Type:</b> <code>1D</code>, a single parameter controls the blending of all clips in the blend tree. <code>2D</code>, two parameters are used to control the blending among clips. For 2D there are some variations as <code>2D Simple Directional</code>, <code>2D Freeform Directional</code> and <code>2D Freeform Cartesian</code>, any of them can have points freely positioned in the cartesian plane, the difference is how the interpolation of the clips are calculated.</li>
			<li><b>Parameters:</b> The drop-down menu to select which parameter each coordinate represents.</li>
			<li><b>Blending Diagram:</b> The graphical representation of the position of each clip and its influence.</li>
			<li><b>Motion List:</b> The list of clips and child blend trees of this blend tree. Depending of which blend type is selected it shows the 1D or 2D coordinates of the clip, its play speed and mirroring option.</li>
			<li><b>Compute Positions:</b> Auto-position the clips based on it's root motion. The computation can be based in the position or (angular) velocity of the root motion.</li>
		</ul>
	</div>
</div>
<br>
<p>The range of the parameters are automatically computed from the position of the clips. When setting values outside this range, they are clipped.</p>

<p>When using blend trees, besides right positioning the clips in the 1D/2D graph, it's important to have the clips which are controlled by the same parameter to be synchronized in its length and cycle. Otherwise the blend in-between motions can be awkward. One common example where this behavior can happen is when blending between mirrored animations like "walking left" mirrored to "walking right" or transitions between "walk" and "run".</p>

<div style="margin: 3rem;">
	<div class="image 50%" style="text-align: center; float: left;">
		Synchronized legs with correct length & cycle.<br>
		<div class="video-container">
		<video width="428" height="334" src="images/sync.webm" frameborder="0" controls></video>
		</div>
	</div>
	<div class="image 50%" style="text-align: center;">
		Unsynchronized legs with incorrect length & cycle.<br>
		<div class="video-container">
		<video width="428" height="334" src="images/unsync.webm" frameborder="0" controls></video>
		</div>
	</div>
</div>
<br>

<h3>Physics, Colliders and Raycast</h3>

<p>Interacting with the environment in a meaningful way requires our dog to behave similar as a physical body. For example not occupying the same space of another body at the same time or trespassing walls, jumping and falling according with gravity etc. Those behaviors are accomplished by using the <i>physics engine</i> to handle the forces and velocities acting in a body and <i>colliders</i> to detect when objects are intersecting each other. Together with them there are the <i>raycast</i> which provides a way to detect intersections with basic geometries (rays, boxes, spheres, capsules, etc) along a given direction.</p>

<p>One of the components that makes a gameObject interact with the physics engine is the <code>RigidBody</code>, as the name suggests, it is a non-deformable body. Here, being non-deformable means the physics engine does not change the body form (mesh), but its position and rotation. By any means, this does not prevent any other source of changing the mesh vertices and transformation. The following parameters can be controlled in the RigidBody component:</p>

<div class="spotlight">
	<div class="image flush">
		<img class="image" src="images/rigidbody.png"></img>
	</div>
	<div class="inner2">
		<ul>
			<li><b>Mass:</b> The body mass.</li>
			<li><b>Drag:</b> The air resistance against linear movement forces.</li>
			<li><b>Angular Drag:</b> The air resistance against angular movement torque.</li>
			<li><b>Gravity:</b> Enable/disable gravity effect over the body.</li>
			<li><b>Is Kinematic:</b> When enabled it disables the effect of the physics engine over the object.</li>
			<li><b>Interpolate:</b> Defines how the movement between frames is interpolated, <code>none</code>, <code>interpolate</code> based on previous frame,  <code>extrapolate</code> based on an estimate of the next frame.</li>
		</ul>
	</div>
</div>

<ul>
<li><b>Collision Detect: </b><code>Discrete</code> per frame detection, <code>Continuous</code> detect collisions against static objects between frames, prevent fast moving objects which in the exact frame time are not colliding but in the time between frames would collide, <code>Continuous Dynamic</code> same as continuous but also takes in account dynamic objects in the scene, <code>Continuous Speculative</code> same as dynamic but using a different method to estimate the collision, usually cheaper than dynamic.</li>
<li><b>Constraints:</b> Individual selection of axis where translation and/or rotation cannot be changed by the physics engine (frozen).</li>
</ul>
<br>

<p>The next component is the collider. Unity offer various types of colliders which varies in its geometries, here our dog uses a simple </i>BoxCollider</i>. The next image shows the dog with its box, superposed with the inspector of the BoxCollider.
</p>
<img class="image fit" src="images/collider.png"></img>

<p>The collider properties are:</p>
<ul>
   <li><b>Is Trigger:</b> When enabled it is ignored by the physics engine and it's only used to trigger events. For example it could be used to check when a projectile entered a given volume without interacting with it.</li>
   <li><b>Material:</b> The physical material of the object, it affects for example the friction, if a collision is elastic or not etc. Some default materials are available with the Unity Standard Assets.</li>
   <li><b>Center:</b> Center of the box collider in object space coordinates.</li>
   <li><b>Size:</b> Extents of the box in object space coordinates.</li>
</ul>

<p>Next we have the ray casting tools. It can be used in various ways, but the most common for character controller is in a "sensor like" fashion. While we call it ray cast, you can cast spheres, capsules, lines and boxes along a direction too. One good example of usage is checking if the character have its feet grounded. You can simple cast a ray starting a little above its feet and check if it hits the ground within a distance \(\delta\). Inside a C# script it would look like:</p>

<div id="raycast"><script>loadGist('raycast','https://gist.github.com/caioc2/7c0703ac3a46054b1b881e0bd353dca5.json')</script></div>

<p>The basic syntax is <code>ray origin</code>, <code>direction</code>, <code>hit information</code>, <code>maximum distance</code> returning true if any object was hit within the maximum distance. It can also accept other parameters as if it should trigger actions, which layers it should check against and for other geometries (box, shpere, etc) their respective parameters which can be found in the <a href="https://docs.unity3d.com/ScriptReference/Physics.html">Unity Scripting Reference</a></p>